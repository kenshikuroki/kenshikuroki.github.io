#!/usr/bin/env python3
"""
Enhanced INSPIRE-HEP Metadata Updater
INSPIRE-HEPã‹ã‚‰åŒ…æ‹¬çš„ãªè«–æ–‡æƒ…å ±ã‚’å–å¾—ã—ã¦publications.jsonã‚’æ›´æ–°ã—ã¾ã™
"""

import requests
import json
import time
from datetime import datetime
from pathlib import Path
import re
from typing import Dict, List, Optional, Any

class EnhancedCitationUpdater:
  def __init__(self, json_path="assets/data/publications.json"):
    self.json_path = Path(json_path)
    self.base_url = "https://inspirehep.net/api"

  def extract_arxiv_id(self, arxiv_string: str) -> Optional[str]:
    """arXivæ–‡å­—åˆ—ã‹ã‚‰IDã‚’æŠ½å‡º"""
    patterns = [
      r'(\d{4}\.\d{4,5})',  # æ–°å½¢å¼: 2410.01204
      r'([a-z-]+/\d{7})',   # æ—§å½¢å¼: hep-ph/0123456
    ]
    for pattern in patterns:
      match = re.search(pattern, arxiv_string)
      if match:
        return match.group(1)
    return None

  def extract_doi(self, doi_string: str) -> Optional[str]:
    """DOIæ–‡å­—åˆ—ã‹ã‚‰DOIã‚’æŠ½å‡º"""
    patterns = [
      r'doi\.org/(.+)',
      r'(10\.\d+/.+)',
    ]
    for pattern in patterns:
      match = re.search(pattern, doi_string)
      if match:
        return match.group(1)
    return None

  def search_paper_comprehensive(self, publication: Dict) -> Optional[Dict]:
    """è¤‡æ•°ã®æ–¹æ³•ã§è«–æ–‡ã‚’æ¤œç´¢ã—ã€åŒ…æ‹¬çš„ãªæƒ…å ±ã‚’å–å¾—"""
    # 1. æ—¢å­˜ã®INSPIRE-HEP IDãŒã‚ã‚‹å ´åˆ
    if publication.get('inspire_id'):
      result = self.get_paper_by_inspire_id(publication['inspire_id'])
      if result:
        return result
    # 2. arXiv IDã§æ¤œç´¢
    for link in publication.get('links', []):
      if link.get('type') == 'arxiv':
        arxiv_id = self.extract_arxiv_id(link.get('text', ''))
        if arxiv_id:
          result = self.search_by_arxiv(arxiv_id)
          if result:
            return result
          time.sleep(1)
    # 3. DOIã§æ¤œç´¢
    for link in publication.get('links', []):
      if link.get('type') == 'doi':
        doi = self.extract_doi(link.get('url', ''))
        if doi:
          result = self.search_by_doi(doi)
          if result:
            return result
          time.sleep(1)
    # 4. ã‚¿ã‚¤ãƒˆãƒ«ã§æ¤œç´¢ï¼ˆæœ€å¾Œã®æ‰‹æ®µï¼‰
    if publication.get('title'):
      result = self.search_by_title(publication['title'])
      if result:
        return result
    return None

  def get_paper_by_inspire_id(self, inspire_id: str) -> Optional[Dict]:
    """INSPIRE-HEP IDã§è«–æ–‡æƒ…å ±ã‚’å–å¾—"""
    try:
      response = requests.get(f"{self.base_url}/literature/{inspire_id}")
      response.raise_for_status()
      data = response.json()
      return self.extract_paper_metadata({'metadata': data['metadata'], 'id': inspire_id})
    except Exception as e:
      print(f"INSPIRE-HEP ID search failed for {inspire_id}: {e}")
    return None

  def search_by_arxiv(self, arxiv_id: str) -> Optional[Dict]:
    """arXiv IDã§æ¤œç´¢"""
    try:
      response = requests.get(f"{self.base_url}/literature",
                            params={'q': f'eprint:{arxiv_id}', 'size': 1})
      response.raise_for_status()
      data = response.json()
      if data['hits']['total'] > 0:
        return self.extract_paper_metadata(data['hits']['hits'][0])
    except Exception as e:
      print(f"arXiv search failed for {arxiv_id}: {e}")
    return None

  def search_by_doi(self, doi: str) -> Optional[Dict]:
    """DOIã§æ¤œç´¢"""
    try:
      response = requests.get(f"{self.base_url}/literature",
      params={'q': f'doi:{doi}', 'size': 1})
      response.raise_for_status()
      data = response.json()
      if data['hits']['total'] > 0:
        return self.extract_paper_metadata(data['hits']['hits'][0])
    except Exception as e:
      print(f"DOI search failed for {doi}: {e}")
    return None

  def search_by_title(self, title: str) -> Optional[Dict]:
    """ã‚¿ã‚¤ãƒˆãƒ«ã§æ¤œç´¢ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰"""
    try:
      # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      clean_title = re.sub(r'[^\w\s]', ' ', title).strip()
      query_title = ' '.join(clean_title.split()[:5])  # æœ€åˆã®5å˜èªã‚’ä½¿ç”¨
      response = requests.get(f"{self.base_url}/literature",
      params={'q': f'title:"{query_title}"', 'size': 5})
      response.raise_for_status()
      data = response.json()
      # ã‚¿ã‚¤ãƒˆãƒ«ã®é¡ä¼¼åº¦ã‚’ãƒã‚§ãƒƒã‚¯
      for hit in data['hits']['hits']:
        inspire_title = hit['metadata'].get('titles', [{}])[0].get('title', '')
        if self.title_similarity(title, inspire_title) > 0.8:
          return self.extract_paper_metadata(hit)
    except Exception as e:
      print(f"Title search failed for '{title}': {e}")
    return None

  def extract_paper_metadata(self, hit: Dict) -> Dict:
    """INSPIRE-HEP APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰å¿…è¦ãªæƒ…å ±ã‚’æŠ½å‡º"""
    metadata = hit['metadata']
    result = {
      'inspire_id': str(hit['id']),
      'citations': metadata.get('citation_count', 0),
      'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    # ã‚¿ã‚¤ãƒˆãƒ«
    titles = metadata.get('titles', [])
    if titles:
      result['title'] = titles[0].get('title', '')
    # è‘—è€…ãƒªã‚¹ãƒˆ
    authors = metadata.get('authors', [])
    if authors:
      author_names = []
      for author in authors:
        full_name = author.get('full_name', '')
        if full_name:
          author_names.append(full_name)
      result['authors'] = ', '.join(author_names)
    # å‡ºç‰ˆæƒ…å ±
    pub_info = metadata.get('publication_info', [])
    if pub_info:
      pub = pub_info[0]
      result['journal'] = pub.get('journal_title', '')
      result['volume'] = pub.get('journal_volume', '')
      if pub.get('page_start') and pub.get('page_end'):
        result['pages'] = f"pub.get('page_start')-pub.get('page_end')"
      elif pub.get('page_start'):
        result['pages'] = pub.get('page_start')
      elif pub.get('artid'):
        result['pages'] = pub.get('artid')
      result['year'] = pub.get('year', '')
    # å‡ºç‰ˆå¹´ï¼ˆä»£æ›¿ï¼‰
    if not result.get('year'):
      preprint_date = metadata.get('preprint_date', '')
      if preprint_date:
        result['year'] = preprint_date[:4]
    # arXivæƒ…å ±
    arxiv_eprints = metadata.get('arxiv_eprints', [])
    if arxiv_eprints:
      result['arxiv_id'] = arxiv_eprints[0].get('value', '')
      result['arxiv_categories'] = arxiv_eprints[0].get('categories', [])
    # DOI
    dois = metadata.get('dois', [])
    if dois:
      result['doi'] = dois[0].get('value', '')
    # URLs
    urls = metadata.get('urls', [])
    result['urls'] = []
    for url in urls:
      result['urls'].append({
        'description': url.get('description', ''),
        'value': url.get('value', '')
      })
    return result

  def title_similarity(self, title1: str, title2: str) -> float:
    """ç°¡å˜ãªã‚¿ã‚¤ãƒˆãƒ«é¡ä¼¼åº¦è¨ˆç®—"""
    # å˜èªãƒ¬ãƒ™ãƒ«ã§ã®é¡ä¼¼åº¦ï¼ˆJaccardä¿‚æ•°ï¼‰
    words1 = set(re.findall(r'\w+', title1.lower()))
    words2 = set(re.findall(r'\w+', title2.lower()))
    if not words1 or not words2:
      return 0.0
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    return intersection / union if union > 0 else 0.0

  def merge_metadata(self, current_pub: Dict, inspire_data: Dict) -> Dict:
    """ç¾åœ¨ã®å‡ºç‰ˆç‰©ãƒ‡ãƒ¼ã‚¿ã¨INSPIRE-HEP ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸"""
    updated_pub = current_pub.copy()
    # å¸¸ã«æ›´æ–°ã™ã‚‹é …ç›®
    always_update = ['citations', 'last_updated']
    # ç©ºã®å ´åˆã®ã¿æ›´æ–°ã™ã‚‹é …ç›®
    update_if_empty = ['title', 'authors', 'inspire_id']
    # ãƒªãƒ³ã‚¯æƒ…å ±ã®æ›´æ–°
    update_links = True
    for key, value in inspire_data.items():
      if key in always_update:
        updated_pub[key] = value
      elif key in update_if_empty and (not updated_pub.get(key) or updated_pub.get(key) == ''):
        updated_pub[key] = value
      elif key == 'categories' and value:
        updated_pub[key] = value
      elif key == 'urls' and value:
        updated_pub[key] = value
    # ãƒªãƒ³ã‚¯æƒ…å ±ã®è‡ªå‹•æ›´æ–°
    if update_links:
      updated_pub = self.update_links(updated_pub, inspire_data)
    return updated_pub

  def update_links(self, publication: Dict, inspire_data: Dict) -> Dict:
    """ãƒªãƒ³ã‚¯æƒ…å ±ã‚’æ›´æ–°"""
    links = publication.get('links', [])
    # DOI ãƒªãƒ³ã‚¯ã®è¿½åŠ /æ›´æ–°
    if inspire_data.get('doi'):
      doi_exists = any(link.get('type') == 'doi' for link in links)
      if not doi_exists:
        links.append({
          'type': 'doi',
          'text': f"{inspire_data['journal']} {inspire_data['volume']}, {inspire_data['pages']} ({inspire_data['year']})",
          'url': f"https://doi.org/{inspire_data['doi']}"
        })
    # arXiv ãƒªãƒ³ã‚¯ã®è¿½åŠ /æ›´æ–°
    if inspire_data.get('arxiv_id'):
      arxiv_exists = any(link.get('type') == 'arxiv' for link in links)
      if not arxiv_exists:
        links.append({
          'type': 'arxiv',
          'text': f"arXiv:{inspire_data['arxiv_id']}",
          'url': f"https://arxiv.org/abs/{inspire_data['arxiv_id']}"
        })
    publication['links'] = links
    return publication

  def update_publications(self, backup=True) -> bool:
    """publications.jsonã‚’æ›´æ–°"""
    if not self.json_path.exists():
      print(f"File not found: {self.json_path}")
      return False
    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    try:
      with open(self.json_path, 'r', encoding='utf-8') as f:
        publications = json.load(f)
    except Exception as e:
      print(f"Failed to read JSON file: {e}")
      return False
    print(f"Updating {len(publications)} publications...")
    updated_count = 0
    failed_count = 0
    # å„è«–æ–‡ã®æƒ…å ±ã‚’æ›´æ–°
    for i, pub in enumerate(publications):
      print(f"\n[{i+1}/{len(publications)}] Processing: {pub.get('title', 'Unknown Title')[:60]}...")
      inspire_data = self.search_paper_comprehensive(pub)
      if inspire_data:
        old_citations = pub.get('citations', 0)
        updated_pub = self.merge_metadata(pub, inspire_data)
        # å¤‰æ›´ãŒã‚ã£ãŸã‹ãƒã‚§ãƒƒã‚¯
        changes = []
        if old_citations != updated_pub.get('citations', 0):
          changes.append(f"citations: {old_citations} â†’ {updated_pub['citations']}")
        if pub.get('inspire_id') != updated_pub.get('inspire_id'):
          changes.append(f"inspire_id: {pub.get('inspire_id', 'None')} â†’ {updated_pub['inspire_id']}")
        # ãã®ä»–ã®å¤‰æ›´ã‚’ãƒã‚§ãƒƒã‚¯
        for key in ['title', 'authors']:
          old_val = pub.get(key, '')
          new_val = updated_pub.get(key, '')
          if old_val != new_val and new_val:
            changes.append(f"{key}: updated")
        publications[i] = updated_pub
        if changes:
          print(f"  âœ… Updated: {', '.join(changes)}")
          updated_count += 1
        else:
          print(f"  â„¹ï¸  No changes (citations: {updated_pub.get('citations', 0)})")
      else:
        print(f"  âŒ Could not find INSPIRE-HEP data")
        failed_count += 1
      # APIåˆ¶é™å¯¾ç­–
      time.sleep(2)
    # æ›´æ–°ã•ã‚ŒãŸJSONã‚’ä¿å­˜
    try:
      with open(self.json_path, 'w', encoding='utf-8') as f:
        json.dump(publications, f, indent=2, ensure_ascii=False)
      print(f"\n" + "="*50)
      print(f"âœ… Update completed!")
      print(f"ğŸ“Š Updated: {updated_count} publications")
      print(f"âŒ Failed: {failed_count} publications")
      print(f"ğŸ“„ File saved: {self.json_path}")
      return True
    except Exception as e:
      print(f"Failed to save JSON file: {e}")
      return False

  def generate_report(self) -> Dict:
    """æ›´æ–°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    if not self.json_path.exists():
      return {}
    try:
      with open(self.json_path, 'r', encoding='utf-8') as f:
        publications = json.load(f)
      total_citations = sum(pub.get('citations', 0) for pub in publications)
      with_inspire_id = sum(1 for pub in publications if pub.get('inspire_id'))
      categories = {}
      for pub in publications:
        for cat in pub.get('categories', []):
          categories[cat] = categories.get(cat, 0) + 1
      return {
        'total_publications': len(publications),
        'total_citations': total_citations,
        'with_inspire_id': with_inspire_id,
        'coverage': f"{with_inspire_id/len(publications)*100:.1f}%",
        'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
      }
    except Exception as e:
      print(f"Report generation failed: {e}")
      return {}

def main():
  print("Enhanced INSPIRE-HEP Metadata Updater")
  print("=" * 50)
  updater = EnhancedCitationUpdater()
  # æ›´æ–°å‰ã®ãƒ¬ãƒãƒ¼ãƒˆ
  print("Current status:")
  report = updater.generate_report()
  for key, value in report.items():
    print(f"  {key}: {value}")
  print("\nStarting update...")
  success = updater.update_publications()
  if success:
    print("\nğŸ‰ Update completed successfully!")
    # æ›´æ–°å¾Œã®ãƒ¬ãƒãƒ¼ãƒˆ
    print("\nUpdated status:")
    new_report = updater.generate_report()
    for key, value in new_report.items():
      print(f"  {key}: {value}")
  else:
    print("\nâŒ Update failed. Please check the error messages above.")

if __name__ == "__main__":
  main()
